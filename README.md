# Покупка билетов в кино

## Описание системы
Система позволяет:  
 - просмотреть расписание фильмов на текущую дату
 - выбрать фильм и выбрать свободное место в зале. Место имеет 3 состояния: свободно, занято, куплено мною 
 - просмотреть список моих билетов. На 1 фильм можно купить несколько билетов
 - билет несет полную информацию о сеансе: фильм, зал, место
 - можно заходить под разными пользователями и видеть свободные места

## Настройка проекта
1) Создать в корне `.env` файл или выполнить команду `cp .env.example .env`.  
Важно: новый файл должен содержать **все** настройки из файла `.env.example` в случае ручного создания  
2) Поднять posgtre-БД в докере командой `make docker-up` (make docker-down - останавливает бд)  
3) Выполнить миграции `make migrate`. Важно. Если docker из п2 не поднялся еще - будет ошибка. Надо подождать пару минут

### Запуск gRPC server-client
1) В `.env` файле пропишите порты, на которых хотите поднять сервер. По-умолчанию уже стоят client:8090(rest api) и 8091(grpc), backend: 8081(grpc)
2) Команда `make run-server` запускает сервер backend 
3) Команда `make run-client` запускает клиента + resp proxy
4) Команда `make run-consumer` запускает kafka consumer
5) В корне сайта лежит файл `rest-api.http`, в котором описаны все rest commands как примеры. Рабочие и можно их запускать

#### Особенность gRPC server 
Т к билеты в кино покупать могут разные пользователи, то пользователя надо как-то идентифицировать. Если в случае tgBot мы сразу знали имя и id пользователя,
то чтобы не ломать всю логику была создана упрощенная аудентификация по токену, который состоит из "name-id" пользователя.  
**Токен** получить можно командой `curl -X POST http://localhost:8090/v1/auth -d '{"name": "dima"}'`.  
Далее в каждом запросе в **header** надо будет слать заголовок, например `Token: dido-1`

#### Swagger (json)
Сваггер доступен попути `http://localhost:8090/swagger`. Порт береться из настройки окружения `REST_PORT=8090`

### Kafka (broker)
Часть сервисов общаются через kafka. В docker добавлены все настройки и topic-и. Для прослушивания kafka надо звпустить 
consumer `make run-consumer`  
Так же доступно kafka-ui по адресу `http://localhost:8095/ui/clusters`

#### expvar
Посмотреть счетчики по consumer kafka можно по пути `http://localhost:8020/debug/vars`

### Миграции
Для работы с миграциями надо установить пакет [Goose](https://pressly.github.io/goose/) и настроить переменные в файле `.env`(по умолчанию уже стоят значения)  
Все миграции находятся в папке `/migrations`  
Команды миграции:  
`make migration name=<name>` - создать миграцию с именем  
`make migrate-status` - посмотреть статистику по миграциям  
`make migrate` - запустить миграции

### Тестирование
Для тестирование поднимается отдельная БД в своем контейнере. Настройки начинаются с QA(см .env.example). Все эти настройки должны быть 
в файле `.env`. Каждый тест всегда очищает бд в конце(truncate). Поэтому **ВАЖНО**, чтобы server так же смотрел на тестовую бд.   
Для этого надо подправить следующие настройки в `.env` и перезапустить server  
`DB_PORT=<QA_DB_PORT>` - заменить на значение из QA  
`DB_NAME=<QA_DB_NAME>` - заменить на значение из QA 
Т. о. наш сервер будет смотреть на qa-db и интергарционные тесты пройдут удачно.
Так же при *первом запуске* надо запустить миграции `make .migrate-qa`  

#### Запуск unit-test
`make .test`

### Генератор структур
Файл генераци лежит по пути `./third_party/generators/fixture/generator.go`, там же находиться и тестовый файл для генерации.  
Команда запуска:    
`go run generator.go --filename ./test/structures.go` - запускать из каталога файла(перейти в каталог)  
Можно так же запустить через make из корня сайта    
`make generate-fixture filename=./test/structures.go` - где filename - путь от исполняющего файла генерации. Если оставить его пустым, 
то подхватится тестовый файл ./test/structures.go. Пример запуска с тестовым файлом `make .generate-fixture`.  
Сгенерированные файлы будут лежать в том же каталоге, что и файл, с которого генерим

